{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The selected Dataset was stored in Google Drive, So firstly Colab had to be Given Access to the files in Drive"
      ],
      "metadata": {
        "id": "SihIwLBPTdWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "X-sLqatcTdkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4eb3e7-6f0e-4426-e022-a4d767f9617d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " STEP 1: Data Loading\n"
      ],
      "metadata": {
        "id": "prLvh1oNwuHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset using the provided path\n",
        "data_path = \"/content/drive/MyDrive/Breast_Cancer.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "FJdUgPq0zOZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1.1 Data Exploration"
      ],
      "metadata": {
        "id": "u5muO8tPV4wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information about the dataset\n",
        "df.info()\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "id": "qWDghVgTV49K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " STEP 2: Data Preprocessing"
      ],
      "metadata": {
        "id": "UVe32dYaw3sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'diagnosis' column to binary representation\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "y = df['diagnosis'].values\n",
        "df = df.drop(columns=['id', 'diagnosis', 'Unnamed: 32'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.values, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "q9nEqm-sw318"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "STEP 3: Helper Functions\n"
      ],
      "metadata": {
        "id": "iVU25b87xaGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def entropy(y):\n",
        "    \"\"\"Compute the entropy of the given labels.\"\"\"\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    probabilities = counts / len(y)\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "def info_gain(y_left, y_right, parent_entropy):\n",
        "    \"\"\"Calculate information gain from a potential split.\"\"\"\n",
        "    n = len(y_left) + len(y_right)\n",
        "    child_entropy = (len(y_left) / n) * entropy(y_left) + (len(y_right) / n) * entropy(y_right)\n",
        "    return parent_entropy - child_entropy\n"
      ],
      "metadata": {
        "id": "Sx8s-O4_xaSK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "STEP 4: Building the Tree\n"
      ],
      "metadata": {
        "id": "_QbmDhQZxmmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_tree(X, y, depth=0, max_depth=5):\n",
        "    \"\"\"\n",
        "    Recursively build the decision tree.\n",
        "    - Stop the recursion if all samples have the same label or if depth equals max_depth.\n",
        "    - For each feature, check every unique value as a potential split.\n",
        "    - Apply the best split and continue recursively.\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "    unique_classes = np.unique(y)\n",
        "\n",
        "    # Stopping criteria\n",
        "    if len(unique_classes) == 1 or depth == max_depth:\n",
        "        return int(unique_classes[0])\n",
        "\n",
        "    # Initialize best split parameters\n",
        "    best_gain = 0\n",
        "    best_threshold = None\n",
        "    best_index = None\n",
        "    parent_entropy = entropy(y)\n",
        "\n",
        "    # Search for the best split\n",
        "    for index in range(n_features):\n",
        "        thresholds = np.unique(X[:, index])\n",
        "        for threshold in thresholds:\n",
        "            y_left = y[X[:, index] < threshold]\n",
        "            y_right = y[X[:, index] >= threshold]\n",
        "\n",
        "            # Skip this split if it doesn't divide the dataset.\n",
        "            if len(y_left) == 0 or len(y_right) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate gain and update best split if needed\n",
        "            gain = info_gain(y_left, y_right, parent_entropy)\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_threshold = threshold\n",
        "                best_index = index\n",
        "\n",
        "    # If no gain, return majority class\n",
        "    if best_gain == 0:\n",
        "        return int(np.bincount(y).argmax())\n",
        "\n",
        "    # Recursive calls for left and right subtrees\n",
        "    left_mask = X[:, best_index] < best_threshold\n",
        "    right_mask = X[:, best_index] >= best_threshold\n",
        "\n",
        "    left_tree = build_tree(X[left_mask], y[left_mask], depth + 1, max_depth)\n",
        "    right_tree = build_tree(X[right_mask], y[right_mask], depth + 1, max_depth)\n",
        "\n",
        "    return (best_index, best_threshold, left_tree, right_tree)\n"
      ],
      "metadata": {
        "id": "ISb7kE6TxmNr"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 5: Prediction Function\n"
      ],
      "metadata": {
        "id": "CKM9-lBtxmAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sample, tree):\n",
        "    \"\"\"Recursively predict the class of a sample using the decision tree.\"\"\"\n",
        "    # If we reach a leaf node (integer), return the class\n",
        "    if isinstance(tree, int):\n",
        "        return tree\n",
        "\n",
        "    # Extract tree parameters\n",
        "    index, threshold, left_tree, right_tree = tree\n",
        "    if sample[index] < threshold:\n",
        "        return predict(sample, left_tree)\n",
        "    return predict(sample, right_tree)"
      ],
      "metadata": {
        "id": "Q1g4vSITxzpm"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6: Model Evaluation\n"
      ],
      "metadata": {
        "id": "ReUCaXZEx98c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Construct the decision tree\n",
        "tree_root = build_tree(X_train, y_train, depth=0, max_depth=5)\n",
        "\n",
        "# Predict labels for test set and calculate accuracy\n",
        "predicted_labels = [predict(sample, tree_root) for sample in X_test]\n",
        "accuracy = np.mean(predicted_labels == y_test)\n",
        "print(f\"Decision Tree Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaYU81-Jx9kO",
        "outputId": "f5f1f43a-8a49-4c78-8338-1afc525b2cca"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 95.61%\n"
          ]
        }
      ]
    }
  ]
}